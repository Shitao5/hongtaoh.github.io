<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>贝叶斯 on 郝鸿涛::Hongtao Hao</title>
    <link>https://hongtaoh.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/</link>
    <description>Recent content in 贝叶斯 on 郝鸿涛::Hongtao Hao</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 02 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hongtaoh.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>贝叶斯统计思想入门（二)：概率</title>
      <link>https://hongtaoh.github.io/cn/2020/02/02/bayesian-stats-chapter4/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hongtaoh.github.io/cn/2020/02/02/bayesian-stats-chapter4/</guid>
      <description>上篇，也就是第二章，k老师主要是简单介绍了一下贝叶斯的方法。第三章是介绍了 r 语言的基本操作，这里不再介绍。从第四章开始，整本书渐渐进入主体，开始涉及贝叶斯的核心。
第四章开始讲概率 (probability)。概率是用来描述不确定性 (uncertainty) 的。假如我现在抛一枚硬币，掉下来之后有可能是正面朝上，也可能是背面朝上。每当我们讨论一种结果的可能性的时候，我们其实在头脑里想到了所有可能的结果，这些所有可能的结果叫做样本空间 (sample space)。
如果这个硬币质地良好，那么正面朝上的概率是 50%。如果质地粗糙，那么正面朝上的概率有可能大于50%，也可能小于50%。我们用希腊字母 θ 来表示正面朝上的概率。如果 $\theta = 50\%$ ，那说明硬币质地良好。
另一个层面，我们对于 $\theta$ 的值其实也是有预设的。如果这枚硬币是国家铸币厂生产的，那么 θ=50% 的概率会很高，如 $p(\theta = 0.5)＝0.99$, 如果这枚硬币是小作坊生产的，那么 $p(\theta = 0.5)$ 可能只有0.01.
回到样本空间这个概念。抛一枚硬币这个事件的样本空间有2种可能的结果：正面朝上、背面朝上。猜测硬币的质地时，样本空间有无数种可能的结果：从 $\theta ＝0.0$ 到 $\theta ＝1.0$ 之间所有的数字都有可能。
你可能像我一样对掷硬币已经不耐烦了，因为已经在太多教材中看过。但是k教授说到，掷硬币可以用来代表几乎所有二元性的事件：选a还是选b、药物有效还是无效、正确还是错误等等。所以我们还是要研究掷硬币。
当我们说，一个质地良好的硬币，正面朝上的概率是50%时，我们是说，将这个硬币抛掷无数次，有50%的次数是正面朝上的。也就是说，这个概率是指，从长远来看的相对频率。
有两种方法来获取这个从长远来看的相对频率：
 模拟； 数学公式推导  第一种方法，模拟。我们用 R 语言来模拟。假设计算机预算 $\theta = 0.8$，也就是正面朝上的概率是 80％，但是我们不知道。我们只能通过观察计算机的掷币结果来推测。
下面我们在计算机上模拟抛掷一枚 $\theta = 0.8$ 的硬币一万次。代码1如下：
n &amp;lt;- 10000 pheads &amp;lt;- 0.8 flips&amp;lt;-sample (x=c(0,1),prob=c(1-pheads, pheads),size=n, replace=TRUE) num.heads &amp;lt;- cumsum(flips) total.toss &amp;lt;- c(1:n) prob.</description>
    </item>
    
    <item>
      <title>贝叶斯统计思想入门（一)：概述</title>
      <link>https://hongtaoh.github.io/cn/2020/01/18/bayesian-stats-chapter2/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hongtaoh.github.io/cn/2020/01/18/bayesian-stats-chapter2/</guid>
      <description>前言：这篇文章是我上约翰.克鲁斯克老师 (John Kruschke) 的《贝叶斯数据分析》 (P533: Bayesian Data Analysis) 这门课时，在课下看他的教材 Doing Bayesian Data Analysis (Second Edition) 所做的笔记。
贝叶斯的本质是对于可能性1(credibility) 的重置 (reallocation)。比如，早上刚出家门，你看到门前地面是湿的。这个有很多种可能的原因：下雨了、小孩子撒尿了、环卫工人刚打扫了、物业洒水车刚洒了水、有人不小心把水杯里的水洒出来了、外星人来过自己的家然后离开的时候不小心留下的痕迹&amp;hellip;这些所有的可能，在我们获得进一步数据之前，都有着自己的先验概率 (prior probability)。这些先验概率，是我们主观上认为的可能性，比如根据我们往常的生活经验，下雨的可能性要比外星人到访高的多。虽然高得多，我们获得的信息毕竟是有限的，因为我们只是观察了门前的一小块地。因此，这些可能性都是存在的。
然后，我们接着在路上走，发现不仅整条路都是湿的，而且房屋顶都是湿的，那么我们对概率进行重置：下雨的可能性进步一提升，而之前有可能的洒水车洒过水的可能性下降，因为洒水车不可能把水洒到房顶上。
Kruschke 老师的教材中的图2.1对这一过程进行了进一步阐释。这张图展示了从一开始认为 A, B, C, D 都有可能是罪犯，而且可能性相同，然后一步一步找到新的线索，最后认定 D 是罪犯的过程。
  图2.1, 来源: Kruschke 老师的教材 p.17   贝叶斯统计中很关键的一步是找到可能的解释情况。比如看到门前的路面是湿的，我们已经想到了很多可能的情况，但是不可能把这些情况穷尽。比如，也有可能是一个人在正好经过你的家门的时候，接到一个电话，然后她就哭了，于是门前的路面就湿了，等等。我们也不用试着去穷尽可能情况，只需要找到我们感兴趣的几个情况就好。通过分析，我们可以看到这几个情况是否很好地解释了我们观察到的数据，如果没有，那么我们再去找别的可能的情况。这一过程叫做 posterior predictive check.
很多的时候，一种可能性由一个数学公式来代表，然后看哪个公式可以更好得描述观察到的数据（具体来说，是看是否契合数据的趋势 (trends)以及分散度 (spread) 。从图2.4可以看到， 两个数学公式中，明显第一个公式更好地描述了观察到的数据。需要注意的是，数学公式和观察到的数据之间并不存在因果关系。
  图2.4, 来源: Kruschke 老师的教材 p.23   Kruschke 老师举了一个身高－体重的例子。图2.5左边的图中，小圆圈代表了具体的每个人的身高－体重数据。
  图2.5, 来源: Kruschke 老师的教材 p.26     这里，可能性当然也可以看做概率 (probability)，其实，概率是更为准确的说法。 &amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
  </channel>
</rss>